# ğŸ§© Agora - Modular AI Agent Chat Platform

> **Brutally simple.** Extremely modular. Production-ready.

Agora is a minimal, open-source chat platform for running AI agent frameworks. Think "ChatGPT, but open and composable."

## âœ¨ Features

- ğŸ¯ **Modular Agents** - Each agent self-contained with own config, memory, and tools
- ğŸ”„ **Real-time Streaming** - WebSocket-based token streaming for instant responses
- ğŸ’¾ **Per-Agent Memory** - SQLite-based context management, no token bloat
- ğŸ¨ **Dark Mode UI** - Clean, Raycast-inspired interface
- ğŸš€ **Production Ready** - FastAPI backend, Next.js frontend, Docker deployment
- ğŸ§ª **No Framework Bloat** - Direct OpenAI API calls, no LangChain/CrewAI overhead

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ FRONTEND (Next.js)           â”‚
â”‚  - Chat UI                   â”‚
â”‚  - WebSocket stream          â”‚
â”‚  - Agent selector             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ BACKEND (FastAPI)            â”‚
â”‚  - /chat + /agents routes    â”‚
â”‚  - Orchestrator (router)     â”‚
â”‚  - Context manager per agent â”‚
â”‚  - WebSocket streaming       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ AGENT MODULES                â”‚
â”‚  - paper_writer (academic)   â”‚
â”‚  - shopper (products)        â”‚
â”‚  - [add your own agents]     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ Quick Start

### Prerequisites

- Docker & Docker Compose
- OpenAI API key
- Python 3.10+ (for local development)
- Node.js 20+ (for local development)

### Installation

1. **Clone the repository**

```bash
git clone https://github.com/yourusername/agora.git
cd agora
```

2. **Set up environment variables**

```bash
cp .env.example .env
# Edit .env and add your OPENAI_API_KEY
```

3. **Start with Docker Compose**

```bash
docker compose up
```

4. **Access the app**

- Frontend: http://localhost:3000
- Backend API: http://localhost:8000
- API Docs: http://localhost:8000/docs

## ğŸ“ Project Structure

```
agora/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ main.py                  # FastAPI application
â”‚   â”œâ”€â”€ routes/
â”‚   â”‚   â”œâ”€â”€ chat.py              # Chat endpoints
â”‚   â”‚   â””â”€â”€ agents.py            # Agent management
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ orchestrator.py      # Agent routing & execution
â”‚   â”‚   â”œâ”€â”€ memory.py            # SQLite context management
â”‚   â”‚   â””â”€â”€ router.py            # Intent detection
â”‚   â”œâ”€â”€ agents/
â”‚   â”‚   â”œâ”€â”€ paper_writer/        # Academic writing agent
â”‚   â”‚   â”‚   â”œâ”€â”€ agent.py
â”‚   â”‚   â”‚   â”œâ”€â”€ config.yaml
â”‚   â”‚   â”‚   â”œâ”€â”€ prompt.txt
â”‚   â”‚   â”‚   â””â”€â”€ memory.db
â”‚   â”‚   â””â”€â”€ shopper/             # Shopping agent
â”‚   â”‚       â”œâ”€â”€ agent.py
â”‚   â”‚       â”œâ”€â”€ config.yaml
â”‚   â”‚       â””â”€â”€ tools.py
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ openai_client.py     # OpenAI API wrapper
â”‚       â””â”€â”€ logger.py            # Logging utility
â”‚
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ page.tsx             # Main chat page
â”‚   â”‚   â””â”€â”€ layout.tsx           # Root layout
â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”œâ”€â”€ ChatWindow.tsx       # Message display
â”‚   â”‚   â”œâ”€â”€ MessageBubble.tsx    # Individual messages
â”‚   â”‚   â”œâ”€â”€ InputBar.tsx         # Message input
â”‚   â”‚   â””â”€â”€ AgentSelector.tsx    # Agent dropdown
â”‚   â”œâ”€â”€ hooks/
â”‚   â”‚   â””â”€â”€ useChat.ts           # Zustand state management
â”‚   â””â”€â”€ lib/
â”‚       â”œâ”€â”€ socket.ts            # WebSocket client
â”‚       â””â”€â”€ utils.ts             # Utility functions
â”‚
â””â”€â”€ docker-compose.yml           # Docker orchestration
```

## ğŸ¤– Built-in Agents

### Academic Writer (`paper_writer`)

Writes academic-style paragraphs and summaries.

**Usage:**
- Type naturally: "Write about quantum computing"
- Explicit: `/paper_writer explain machine learning`

### Shopper (`shopper`)

Finds product recommendations (mock data for MVP).

**Usage:**
- Type naturally: "Find me a laptop"
- Explicit: `/shopper best headphones under $200`

## ğŸ”§ Adding Your Own Agent

1. **Create agent folder**

```bash
mkdir backend/agents/your_agent
cd backend/agents/your_agent
```

2. **Create `config.yaml`**

```yaml
name: "Your Agent Name"
description: "What your agent does"
model: "gpt-4o-mini"
max_context: 6000
temperature: 0.7
```

3. **Create `agent.py`**

```python
import yaml
from pathlib import Path
from utils.openai_client import llm_call_with_context

class Agent:
    def __init__(self):
        self.name = "your_agent"
        # Load config...

    async def run(self, query, context, stream=False):
        # Your agent logic here
        return await llm_call_with_context(
            query=query,
            context=context,
            model=self.model,
            stream=stream
        )
```

4. **Register in router** (edit `backend/core/router.py`)

```python
self.agent_keywords = {
    "paper_writer": ["write", "academic", "paper"],
    "shopper": ["buy", "shop", "product"],
    "your_agent": ["keyword1", "keyword2"],  # Add this
}
```

5. **Restart and test!**

## ğŸŒ API Reference

### POST `/chat`

Send a non-streaming chat message.

**Request:**
```json
{
  "query": "Write about AI",
  "session_id": "optional-session-id",
  "agent_name": "paper_writer"
}
```

**Response:**
```json
{
  "response": "AI is a field of...",
  "session_id": "abc123",
  "agent_used": "paper_writer"
}
```

### WebSocket `/chat/ws`

Real-time streaming chat.

**Client sends:**
```json
{
  "query": "Write about AI",
  "agent_name": "paper_writer"
}
```

**Server streams:**
```json
{"type": "start", "session_id": "abc123"}
{"type": "token", "content": "AI"}
{"type": "token", "content": " is"}
{"type": "end", "session_id": "abc123"}
```

### GET `/agents`

List available agents.

**Response:**
```json
{
  "agents": [
    {
      "name": "paper_writer",
      "description": "Writes academic content",
      "model": "gpt-4o-mini"
    }
  ],
  "count": 2
}
```

## ğŸ› ï¸ Development

### Local Backend Development

```bash
cd backend
python -m venv venv
source venv/bin/activate  # or `venv\Scripts\activate` on Windows
pip install -r requirements.txt
uvicorn main:app --reload
```

### Local Frontend Development

```bash
cd frontend
npm install
npm run dev
```

### Running Tests

```bash
# Backend tests (coming soon)
cd backend
pytest

# Frontend tests (coming soon)
cd frontend
npm test
```

## ğŸ³ Deployment

### Production with Docker Compose

```bash
docker compose -f docker-compose.prod.yml up -d
```

### Vercel (Frontend)

```bash
cd frontend
vercel --prod
```

### Fly.io (Backend)

```bash
cd backend
flyctl deploy
```

## ğŸ” Environment Variables

### Backend

- `OPENAI_API_KEY` - Your OpenAI API key (required)

### Frontend

- `NEXT_PUBLIC_API_URL` - Backend API URL (default: http://backend:8000)
- `NEXT_PUBLIC_WS_URL` - WebSocket URL (default: ws://localhost:8000)

## ğŸ§  Memory & Token Management

- Each agent maintains its own SQLite database
- Stores last 5 message exchanges per session
- Automatically summarizes/deletes old context to prevent token bloat
- No shared global context between agents

## ğŸ“ License

MIT License - see LICENSE file for details

## ğŸ¤ Contributing

Contributions welcome! Please read CONTRIBUTING.md first.

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/amazing-agent`)
3. Commit your changes (`git commit -m 'Add amazing agent'`)
4. Push to the branch (`git push origin feature/amazing-agent`)
5. Open a Pull Request

## ğŸ¯ Roadmap

- [ ] Agent registry (install agents via CLI)
- [ ] Multi-user support with authentication
- [ ] Persistent sessions across browser restarts
- [ ] Agent marketplace
- [ ] Voice input/output
- [ ] Mobile app
- [ ] Self-hosted LLM support (Ollama, LocalAI)

## ğŸ“§ Support

- Issues: [GitHub Issues](https://github.com/yourusername/agora/issues)
- Discussions: [GitHub Discussions](https://github.com/yourusername/agora/discussions)

## â­ Star History

If you find Agora useful, please consider starring the repository!

---

**Built with â¤ï¸ by the open-source community**

*Agora v0.1.0 - "The Minimal MVP"*
